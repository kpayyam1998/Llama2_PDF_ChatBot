# Connect Llama3 using Ollama 

## Ollama
    
    * Download ollama exe and install locally 

    * once its installed then 

    ```bash
        ollama list (it will list all the download llm model)
    ```
    ```bash
        ollama pull llama3 (it will download llama3 )
    ```
    ```bash
        ollama run llama3 
    ```
## Llama2 using HuggingFace
    ```bash
        install library
        pip install -r requirements.txt
    ```
    ```bash
        run app
        streamlit run app.py
    ```
